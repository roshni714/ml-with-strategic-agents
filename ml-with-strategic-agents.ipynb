{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf19d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, gaussian_kde, bernoulli\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import basinhopping, newton\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bae3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agent_distribution(n):\n",
    "    eta1 = np.random.uniform(0.01, 0.3, n).reshape(n, 1) #should change this to n x2 x1 so dont have to do as much reshaping later\n",
    "    eta2 = np.random.uniform(0.4, 0.6, n).reshape(n, 1)\n",
    "    etas = np.concatenate((eta1, eta2), axis=1)\n",
    "    gamma1 = np.ones((n, 1))\n",
    "    gamma2 = np.ones((n, 1))\n",
    "    gammas = np.concatenate((gamma1, gamma2), axis=1)\n",
    "    return etas, gammas\n",
    "\n",
    "def compute_score_bounds(beta):\n",
    "    x_box = [np.array([0., 1.]), np.array([1., 0.]), np.array([0., 0.]), np.array([1., 1.])]\n",
    "    scores = [np.matmul(np.transpose(beta),x) for x in x_box]\n",
    "    return min(scores), max(scores)\n",
    "\n",
    "def func_derivative_utility(beta, s, eta, gamma, sigma):\n",
    "    def f(x):\n",
    "        d = x.reshape(2, 1) - eta.reshape(2, 1)\n",
    "        cost_of_gaming= -2 *np.matmul(np.transpose(d), np.diag(gamma))\n",
    "        score = np.matmul(np.transpose(beta), x).item()\n",
    "        allocation = norm.pdf(s - score, loc=0., scale=sigma) * np.transpose(beta)\n",
    "        val = cost_of_gaming + allocation\n",
    "        return (cost_of_gaming + allocation).flatten()\n",
    "    return f\n",
    "\n",
    "def agent_best_response_mapping(beta, s, eta, gamma, sigma):\n",
    "    x0 = np.array([0.5, 0.5])\n",
    "    val = newton(func_derivative_utility(beta, s, eta, gamma, sigma), x0=x0,  maxiter=5000)\n",
    "    val = np.clip(val, a_min=0., a_max=1.)\n",
    "    return val\n",
    "\n",
    "def compute_min_noise(gammas):\n",
    "    min_eigenvalue = [min(gamma) for gamma in gammas]\n",
    "    min_min_eigenvalue = min(min_eigenvalue)\n",
    "    return np.sqrt(1/(2 * min_min_eigenvalue * np.sqrt(2 * np.pi * np.e)))\n",
    "\n",
    "def quantile_best_response_distribution(beta, s, etas, gammas, sigma, score_bounds, q):\n",
    "    agent_best_responses = []\n",
    "    for i in range(len(etas)):\n",
    "        agent_best_responses.append(agent_best_response_mapping(beta, s, etas[i], gammas[i], sigma))\n",
    "    scores = [np.matmul(np.transpose(beta), x) for x in agent_best_responses]\n",
    "    noises = norm.rvs(loc=0., scale=sigma, size=len(etas)).reshape(etas.shape[0], 1)\n",
    "    min_score, max_score = score_bounds\n",
    "    noisy_scores = np.clip(scores + noises, a_min=min_score, a_max=max_score)\n",
    "    noisy_quantile = np.quantile(noisy_scores, q)\n",
    "    return noisy_quantile.item()\n",
    "\n",
    "def quantile_fixed_point(beta, etas, gammas, sigma, score_bounds, q):\n",
    "    thresholds = np.linspace(score_bounds[0], score_bounds[1], 50)\n",
    "    quantile_best_responses = [quantile_best_response_distribution(beta, s, etas, gammas, sigma, score_bounds, q) for s in thresholds]\n",
    "    \n",
    "    plt.plot(thresholds, quantile_best_responses)\n",
    "    \n",
    "    z = np.polyfit(thresholds.flatten(), quantile_best_responses, 3)\n",
    "    f = np.poly1d(z)\n",
    "    \n",
    "#     f = interp1d(thresholds.flatten(), quantile_best_responses, kind=\"cubic\")\n",
    "    granular_thresholds = np.linspace(score_bounds[0], score_bounds[1], 200).flatten()\n",
    "    y = f(granular_thresholds)\n",
    "    plt.plot(granular_thresholds, y)\n",
    "    idx = np.argmin(np.abs(granular_thresholds - y))\n",
    "    noisy_fixed_point = granular_thresholds[idx]\n",
    "    \n",
    "    # should actually make sure that the noise being added is consistent everywhere...\n",
    "    agent_best_responses = []\n",
    "    for i in range(len(etas)):\n",
    "        agent_best_responses.append(agent_best_response_mapping(beta, noisy_fixed_point, etas[i], gammas[i], sigma))\n",
    "    scores = [np.matmul(np.transpose(beta), x) for x in agent_best_responses]\n",
    "    noises = norm.rvs(loc=0., scale=sigma, size=len(etas)).reshape(etas.shape[0], 1)\n",
    "    min_score, max_score = score_bounds\n",
    "    noisy_scores = np.clip(scores + noises, a_min=min_score, a_max=max_score)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return noisy_fixed_point, noisy_scores\n",
    "\n",
    "def fixed_point_iteration(beta, s_prev, etas, gammas, sigma, score_bounds, q, plot=True):\n",
    "    iterations = 50\n",
    "    all_s = [s_prev]\n",
    "    s= s_prev\n",
    "    for k in range(iterations):\n",
    "        new_s = quantile_best_response_distribution(beta, s, etas, gammas, sigma, score_bounds, q)\n",
    "        all_s.append(new_s)\n",
    "        s = new_s\n",
    "        if plot and k % 50 == 0 and k > 0:\n",
    "            plt.plot(list(range(len(all_s))), all_s)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "    return s\n",
    "\n",
    "def decision_maker_loss(treatments, etas, gammas, q):\n",
    "    arr = np.array([0.1, 0.9])\n",
    "    arr = arr/np.sqrt(np.sum((arr ** 2)))\n",
    "    true_beta = arr\n",
    "    \n",
    "    #etas is n x 2\n",
    "    #beta is 2 x 1\n",
    "    true_scores = []\n",
    "    for i in range(len(etas)):\n",
    "        true_scores.append(np.matmul(true_beta, etas[i]).item())\n",
    "    true_scores = np.array(true_scores).reshape(etas.shape[0], 1)\n",
    "    true_quantile = np.quantile(true_scores, q=q)\n",
    "    ideal_treatments = np.zeros(treatments.shape)\n",
    "    ideal_treatments[true_scores>= true_quantile] = 1.\n",
    "    loss_vector = (treatments - ideal_treatments)  ** 2\n",
    "    return loss_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc77241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_beta_experiment(beta, s_beta, etas, gammas, sigma, q, score_bounds, perturbation_size=0.05):\n",
    "    perturbations = (2 * bernoulli.rvs(p=0.5, size=etas.shape[0] * etas.shape[1]).reshape(etas.shape) -1 ) * perturbation_size\n",
    "    scores = []\n",
    "    for i in range(len(etas)):\n",
    "        beta_perturbed = beta + perturbations[i].reshape(etas.shape[1], 1)\n",
    "        #should I project onto unit sphere??\n",
    "        norm_beta_perturbed = np.sqrt(np.sum(beta_perturbed ** 2))\n",
    "        beta_perturbed /= norm_beta_perturbed\n",
    "        agent_best_response = agent_best_response_mapping(beta_perturbed, s_beta, etas[i], gammas[i], sigma)\n",
    "        scores.append(np.matmul(np.transpose(beta_perturbed), agent_best_response))\n",
    "    \n",
    "    noise = norm.rvs(0., scale=sigma, size=etas.shape[0]).reshape(etas.shape[0], 1)\n",
    "    noisy_scores = np.clip(scores + noise, a_min=score_bounds[0], a_max=score_bounds[1])\n",
    "    treatments = (noisy_scores >= s_beta).reshape(etas.shape[0], 1)\n",
    "    \n",
    "    loss_vector = decision_maker_loss(treatments, etas, gammas, q)\n",
    "    \n",
    "    Q = np.matmul(perturbations.T, perturbations)\n",
    "    gamma_loss_beta = np.linalg.solve(Q, np.matmul(perturbations.T, loss_vector))\n",
    "    gamma_pi_beta = np.linalg.solve(Q, np.matmul(perturbations.T, treatments))\n",
    "    \n",
    "    return gamma_loss_beta, gamma_pi_beta\n",
    "\n",
    "\n",
    "def perturb_s_beta_experiment(beta, s_beta, etas, gammas, sigma, q, score_bounds, perturbation_size=0.05):\n",
    "    perturbations = (2 * bernoulli.rvs(p=0.5, size=etas.shape[0]).reshape(etas.shape[0], 1) -1 ) * perturbation_size\n",
    "    scores = []\n",
    "    for i in range(len(etas)):\n",
    "        s_beta_perturbed = s_beta + perturbations[i]\n",
    "        agent_best_response = agent_best_response_mapping(beta, s_beta_perturbed, etas[i], gammas[i], sigma)\n",
    "        scores.append((np.matmul(np.transpose(beta), agent_best_response) + s_beta_perturbed).item())\n",
    "    \n",
    "    \n",
    "    scores = np.array(scores).reshape(etas.shape[0], 1)\n",
    "    noise = norm.rvs(0., scale=sigma, size=etas.shape[0]).reshape(etas.shape[0], 1)\n",
    "    noisy_scores = np.clip(scores + noise, a_min=score_bounds[0], a_max=score_bounds[1])\n",
    "\n",
    "    treatments = (noisy_scores >= s_beta).reshape(etas.shape[0], 1)\n",
    "    \n",
    "    loss_vector = decision_maker_loss(treatments, etas, gammas, 1)\n",
    "    \n",
    "    Q = np.matmul(perturbations.T, perturbations)\n",
    "    gamma_loss_s = Q/np.matmul(perturbations.T, loss_vector)\n",
    "    gamma_pi_s = Q/np.matmul(perturbations.T, treatments)\n",
    "    return gamma_loss_s, gamma_pi_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4bbec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_estimate(arr, x):\n",
    "    kernel = gaussian_kde(arr.flatten())\n",
    "    return kernel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d275d49",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3018339958.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_60408/3018339958.py\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    print(\"Density value\": density_value)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def run_full_game(q, maxiter, learning_rate):\n",
    "    beta = np.array([np.sin(0.5), np.cos(0.5)]).reshape(2, 1)\n",
    "    s_prev = 0.5\n",
    "    losses = []\n",
    "    sigma = compute_min_noise(gammas)\n",
    "    for i in range(maxiter):\n",
    "        score_bounds = compute_score_bounds(beta)\n",
    "        etas, gammas = generate_agent_distribution(500)\n",
    "        \n",
    "        \n",
    "        print(\"Beta:{}\".format(beta))\n",
    "        print(\"Generating fixed point...\")\n",
    "        #s_beta = fixed_point_iteration(beta, s_prev, etas, gammas, sigma, score_bounds, q)\n",
    "        s_beta, noisy_scores = quantile_fixed_point(beta, etas, gammas, sigma, score_bounds, q)\n",
    "        print(\"FP: {}\".format(s_beta))\n",
    "\n",
    "        treatments = (noisy_scores >= s_beta).reshape(etas.shape[0], 1)\n",
    "        loss = np.sqrt(np.sum(decision_maker_loss(treatments, etas, gammas, q)))\n",
    "        deriv_loss_beta, deriv_pi_beta = perturb_beta_experiment(beta, s_beta, etas, gammas, sigma,q, score_bounds)\n",
    "        deriv_loss_s, deriv_pi_s = perturb_s_beta_experiment(beta, s_beta, etas, gammas, sigma, q, score_bounds)\n",
    "        \n",
    "        density_value = density_estimate(noisy_scores, s_beta)\n",
    "        print(\"Density value:{}\".format( density_value))\n",
    "        deriv_s_beta = (1/(density_value + deriv_pi_s) ) * deriv_pi_beta\n",
    "\n",
    "        total_deriv = deriv_loss_beta + deriv_loss_s * deriv_s_beta\n",
    "        new_beta = beta - learning_rate * total_deriv\n",
    "\n",
    "        norm_new_beta = np.sqrt(np.sum(new_beta ** 2))\n",
    "        beta = new_beta/norm_new_beta\n",
    "        s_prev = s_beta\n",
    "        losses.append(loss)\n",
    "        print(\"Loss: {}\".format(loss))\n",
    "    \n",
    "    return losses, beta\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, beta = run_full_game(q=0.8, maxiter=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(losses))), losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e2c095",
   "metadata": {},
   "source": [
    "Testing functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc397fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = np.array([0.5, 0.5]).reshape(1, 2)\n",
    "gammas = np.array([[10., 10.]]).reshape(1, 2)\n",
    "beta = np.array([np.sin(0.5), np.cos(0.5)]).reshape(2, 1)\n",
    "min_score, max_score = compute_score_bounds(beta)\n",
    "thresholds = np.linspace(min_score, max_score, 50)\n",
    "sigma = compute_min_noise(gammas)\n",
    "\n",
    "best_responses = [agent_best_response_mapping(beta, s, etas[0], gammas[0], sigma) for s in thresholds]\n",
    "\n",
    "scores = [np.matmul(np.transpose(beta), x) for x in best_responses]\n",
    "plt.plot(thresholds, scores)\n",
    "plt.plot(thresholds, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6dcda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.linspace(0., 2 * np.pi, 10)\n",
    "etas, gammas = generate_agent_distribution(50)\n",
    "sigma = compute_min_noise(gammas)\n",
    "fp = []\n",
    "for theta in thetas:\n",
    "    beta = np.array([np.sin(theta), np.cos(theta)])\n",
    "    score_bounds_beta = compute_score_bounds(beta)\n",
    "\n",
    "    fp.append()\n",
    "    \n",
    "plt.plot(thetas, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     eta1 = np.tile(np.array([[0.6, 0.8]]), (int(n/2), 1))\n",
    "#     eta2 = np.tile(np.array([[0.1, 0.3]]), (int(n/2), 1))\n",
    "#     gamma1 = np.tile(np.array([1., 1.]), (int(n/2), 1))\n",
    "#     gamma2 = np.tile(np.array([1., 1.]), (int(n/2), 1))\n",
    "    \n",
    "#     etas = np.vstack((eta1, eta2))\n",
    "#     gammas = np.vstack((gamma1, gamma2))\n",
    "\n",
    "eta1 = np.tile(np.array([[0.6, 0.8]]), (int(10/2), 1))\n",
    "eta2 = np.tile(np.array([[0.1, 0.3]]), (int(10/2), 1))\n",
    "np.vstack((eta1, eta2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
